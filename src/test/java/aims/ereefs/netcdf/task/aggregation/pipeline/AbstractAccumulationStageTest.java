package aims.ereefs.netcdf.task.aggregation.pipeline;

import aims.ereefs.netcdf.ApplicationContext;
import aims.ereefs.netcdf.aggregator.AggregationPeriods;
import aims.ereefs.netcdf.input.netcdf.InputDatasetCache;
import aims.ereefs.netcdf.input.netcdf.InputDatasetCacheFactory;
import aims.ereefs.netcdf.output.netcdf.SummaryOperatorDefinitionListBuilder;
import aims.ereefs.netcdf.task.aggregation.DatasetMetadataIdsByInputIdBuilder;
import aims.ereefs.netcdf.task.aggregation.InputDefinitionByVariableNameMapBuilder;
import aims.ereefs.netcdf.task.aggregation.InputIdToInputDefinitionMapBuilder;
import aims.ereefs.netcdf.util.FileUtils;
import aims.ereefs.netcdf.util.TempDirectoryInitialiser;
import aims.ereefs.netcdf.util.file.cache.FileCache;
import au.gov.aims.ereefs.pojo.definition.product.NcAggregateProductDefinition;
import au.gov.aims.ereefs.pojo.metadata.MetadataDao;
import au.gov.aims.ereefs.pojo.metadata.MetadataDaoFileImpl;
import au.gov.aims.ereefs.pojo.task.NcAggregateTask;
import org.assertj.core.api.Assertions;
import org.junit.AfterClass;
import org.junit.BeforeClass;
import ucar.ma2.Array;

import java.io.File;
import java.util.ArrayList;
import java.util.List;

/**
 * Base class for tests of the {@link AccumulationStage} class.
 *
 * @author Aaron Smith
 */
abstract public class AbstractAccumulationStageTest {

    /**
     * References to the various directories used during testing.
     */
    static protected File rootPath = null;
    static protected File inputPath = null;
    static protected File outputPath = null;
    static protected File cachePath = null;
    static protected File dbPath = null;

    /**
     * {@code DAO} for reading/writing metadata to the database.
     */
    static protected MetadataDao metadataDao;

    /**
     * Properties to use when generating the input files.
     */
    final static protected double[] DEPTHS = new double[]{-1.5, -17.75, -49, -103, -200, -315};
    final static protected float[] LATS = {10f, 11f};
    final static protected float[] LONS = {20f, 21f};

    /**
     * Properties to use for defining the {@code Product}.
     */
    static protected String PRODUCT_ID = "test__product";
    static protected String INPUT_ID = "singleInputId";

    /**
     * Prepare the test environment and create the input files.
     */
    @BeforeClass
    static public void rootSetUp() {
        rootPath = new File(TempDirectoryInitialiser.initialise());
        inputPath = new File(rootPath.getAbsolutePath() + File.separator + "inputs" + File.separator);
        inputPath.mkdirs();
        outputPath = new File(rootPath.getAbsolutePath() + File.separator + "outputs" + File.separator);
        outputPath.mkdirs();
        cachePath = new File(rootPath.getAbsolutePath() + File.separator + "cache" + File.separator);
        cachePath.mkdirs();
        dbPath = new File(rootPath.getAbsolutePath() + File.separator + "db" + File.separator);
        dbPath.mkdirs();

        // Instantiate the DAO for reading/writing Metadata.
        metadataDao = new MetadataDaoFileImpl(dbPath.getAbsolutePath());

    }

    /**
     * Teardown the environment, including deleting the input files.
     */
    @AfterClass
    static public void rootTearDown() {
        if (rootPath != null) {
            FileUtils.delete(rootPath);
        }
        rootPath = null;
        inputPath = null;
        outputPath = null;
        cachePath = null;
        dbPath = null;
    }

    /**
     * Utility for executing the standardised {@link #execute(String) test}. The parameters of the
     * test must first be
     * {@link #populate(File[], NcAggregateProductDefinition, NcAggregateTask, MetadataDao)}
     * populated before invoking {@link #execute(String) execute}.
     */
    protected class TestExecutor {

        /**
         * The period over which aggregation is being performed.
         */
        protected AggregationPeriods aggregationPeriod;

        /**
         * The {@code Product} being generated by the {@link AccumulationStage}.
         */
        protected NcAggregateProductDefinition productDefinition;

        /**
         * The list of {@code SummaryOperators} based on the {@link #productDefinition}.
         */
        protected List<NcAggregateProductDefinition.SummaryOperator> summaryOperatorDefinitionList;

        /**
         * The {@code Task} to execute.
         */
        protected NcAggregateTask task;

        /**
         * The {@code DAO} for reading/writing metadata to the database.
         */
        protected MetadataDao metadataDao;

        /**
         * The generated NetCDF files that act as input for the test.
         */
        protected File[] inputDatasetFiles;

        /**
         * The {@code path} for caching files retrieved from the {@link #inputDatasetCache}.
         */
        protected File cachePath;

        /**
         * The {@link InputDatasetCache} for requesting access to the {@link #inputDatasetFiles}.
         */
        protected InputDatasetCache inputDatasetCache;

        public TestExecutor(AggregationPeriods aggregationPeriod,
                            File cachePath) {
            this.aggregationPeriod = aggregationPeriod;
            this.cachePath = cachePath;
        }

        /**
         * Populate the test variables prior to {@link #execute(String) execution} of the test.
         * This method also instantiates an {@link #inputDatasetCache} and the
         * {@link #summaryOperatorDefinitionList}.
         */
        public void populate(File[] inputDatasetFiles,
                             NcAggregateProductDefinition productDefinition,
                             NcAggregateTask task,
                             MetadataDao metadataDao) {
            this.productDefinition = productDefinition;
            this.task = task;
            this.metadataDao = metadataDao;
            this.inputDatasetFiles = inputDatasetFiles;

            // Instantiate the cache for loading input datasets/netcdf files.
            this.inputDatasetCache = InputDatasetCacheFactory.make(
                new FileCache(this.cachePath.getAbsolutePath(), 1),
                metadataDao,
                productDefinition,
                DatasetMetadataIdsByInputIdBuilder.build(task, productDefinition)
            );

            // Build the list of SummaryOperators, based on the variables defined in the Product.
            this.summaryOperatorDefinitionList =
                SummaryOperatorDefinitionListBuilder.build(
                    productDefinition.getAction(),
                    InputDefinitionByVariableNameMapBuilder.build(
                        productDefinition,
                        task,
                        this.inputDatasetCache,
                        InputIdToInputDefinitionMapBuilder.build(productDefinition)
                    ),
                    this.aggregationPeriod,
                    null
                );

        }

        /**
         * Execute the test based on the variables provided via the
         * {@link #populate(File[], NcAggregateProductDefinition, NcAggregateTask, MetadataDao)}
         * method.
         */
        public List<List<Array>> execute(String variableName) {

            // Create new contexts for this test.
            final ApplicationContext applicationContext = new ApplicationContext("test");
            final PipelineContext pipelineContext = new PipelineContext(
                this.task,
                this.productDefinition,
                true,
                null
            );

            // There should be only a single TimeInstant.
            final NcAggregateTask.TimeInstant timeInstant = this.task.getTimeInstants().get(0);
            pipelineContext.setTimeInstant(timeInstant);

            // There should be only a single Input in the TimeInstant.
            pipelineContext.setInput(timeInstant.getInputs().get(0));

            // Choose the SummaryOperator for MEAN temp_hour.
            final NcAggregateProductDefinition.SummaryOperator summaryOperator =
                this.summaryOperatorDefinitionList.stream()
                    .filter(defn -> {
                        return defn.getOperatorType().equalsIgnoreCase("mean") &&
                            defn.getInputVariables().size() == 1 &&
                            defn.getInputVariables().get(0).endsWith(variableName);
                    })
                    .findFirst()
                    .orElse(null);
            Assertions.assertThat(summaryOperator).isNotNull();
            pipelineContext.setSummaryOperator(summaryOperator);

            // Instantiate and execute the processing pipeline.
            final WriteTimeSliceInterceptorStage writeTimeSliceStage = new WriteTimeSliceInterceptorStage(
                pipelineContext
            );
            final RegularGriddingStage regularGriddingStage = new RegularGriddingStage(
                pipelineContext,
                null,
                writeTimeSliceStage
            );
            final AccumulationStage accumulationStage = new AccumulationStage(
                applicationContext,
                pipelineContext,
                this.inputDatasetCache,
                this.aggregationPeriod,
                regularGriddingStage
            );
            accumulationStage.execute();

            return writeTimeSliceStage.getArraysList();
        }

    }

    /**
     * Utility class containing methods useful for executing the tests.
     */
    static protected class TestUtils {

        /**
         * Utility method to expand a single value into a {@code List<Double[]>} result set where
         * every value is the specified value. The result from this method can then be passed to,
         * for example, {@link #validateResults(List, List)}.
         */
        static public List<Double[]> buildResultSetFromSingleValue(double value) {
            return new ArrayList<Double[]>() {{
                int expectedResultSize = 4 * LATS.length * LONS.length;
                Double[] expectedResults = new Double[expectedResultSize];
                for (int index = 0; index < expectedResultSize; index++) {
                    expectedResults[index] = value;
                }
                add(expectedResults);
                expectedResultSize = 2 * LATS.length * LONS.length;
                expectedResults = new Double[expectedResultSize];
                for (int index = 0; index < expectedResultSize; index++) {
                    expectedResults[index] = value;
                }
                add(expectedResults);
            }};
        }

        /**
         * Utility method that compares the actual results against expected results. This method
         * expects only a single output variable.
         */
        static public void validateResults(List<List<Array>> actualResultsByDepthGroupList,
                                           List<Double[]> expectedResultsByDepthGroupList) {

            // The number of depths is greater than the group size for processing (currently 4), so the
            // result should contain two (2) depth groups.
            Assertions
                .assertThat(actualResultsByDepthGroupList)
                .hasSize(2);
            Assertions
                .assertThat(expectedResultsByDepthGroupList)
                .hasSameSizeAs(actualResultsByDepthGroupList);

            // First depth group.
            final List<Array> actualResultsByDepthGroup1 = actualResultsByDepthGroupList.get(0);
            final Double[] expectedResultsByDepthGroup1 = expectedResultsByDepthGroupList.get(0);
            // The actual result should contain data for a single output variable only.
            Assertions.assertThat(actualResultsByDepthGroup1.size()).isEqualTo(1);
            Array actualResultsByOutputVariable = actualResultsByDepthGroup1.get(0);
            Assertions
                .assertThat(actualResultsByOutputVariable.getSize())
                .isEqualTo(4 * LATS.length * LONS.length);
            Assertions
                .assertThat(expectedResultsByDepthGroup1.length)
                .isEqualTo((int) actualResultsByOutputVariable.getSize());
            for (int index = 0; index < actualResultsByOutputVariable.getSize(); index++) {
                Assertions
                    .assertThat(actualResultsByOutputVariable.getDouble(index))
                    .isEqualTo(expectedResultsByDepthGroup1[index]);
            }

            // Second depth group.
            final List<Array> actualResultsByDepthGroup2 = actualResultsByDepthGroupList.get(1);
            final Double[] expectedResultsByDepthGroup2 = expectedResultsByDepthGroupList.get(1);
            // The actual result should contain data for a single output variable only.
            Assertions.assertThat(actualResultsByDepthGroup2.size()).isEqualTo(1);
            actualResultsByOutputVariable = actualResultsByDepthGroup2.get(0);
            Assertions
                .assertThat(actualResultsByOutputVariable.getSize())
                .isEqualTo(2 * LATS.length * LONS.length);
            Assertions
                .assertThat(expectedResultsByDepthGroup2.length)
                .isEqualTo((int) actualResultsByOutputVariable.getSize());
            for (int index = 0; index < actualResultsByOutputVariable.getSize(); index++) {
                Assertions
                    .assertThat(actualResultsByOutputVariable.getDouble(index))
                    .isEqualTo(expectedResultsByDepthGroup2[index]);
            }


        }

    }

}
